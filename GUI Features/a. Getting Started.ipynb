{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images\n",
    "\n",
    "### Reading an image using Open CV\n",
    "Open cv library defines **imread()** for reading the images saved on the disk. It usually takes two arguments. First is Image path, where the image should be in the working directory or the full qualified name of the path should be provided. Second argument is the flag which which specifies the way image should be read. The flags are ***IMREAD_COLOR (default), IMREAD_GRAYSCALE and IMREAD_UNCHANGED***, the flags are integer values, so instead of passing the name only 1,0 or -1 can be passsed respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary imports\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the image in default format ie IMREAD_COLOR\n",
    "my_img = cv2.imread(\"C:\\\\Users\\\\kshitij.saxena\\\\Desktop\\\\stars.png\",cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "#if the image is not found in the defined directory, there won't be any error. But the my_img variable will result in 'null'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying an image using Open CV\n",
    "**imshow()** method will display the image in a window. Window automatically fits to the image size. It takes two arguments, first argument is the name of the Window displaying the image(string type) and second argument will be the image itself.\n",
    "\n",
    "**waitKey()** is a keyboard binding function. Its argument is the time in milliseconds.\n",
    "\n",
    "**destroyAllWindows()** simply destroys all the windows we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('My image',my_img)\n",
    "cv2.waitKey(0) #passing 0 as the argument will make the waitKey method to wait indefinitely\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There might a case where we may need to create the window first and then load the image later sometime. For that purpose we can use **namedWindow()** method which takes the name of the window and a flag as an argument. The flag can either be ***WINDOW_AUTOSIZE*** or ***WINDOW_NORMAL***. In the latter case the window will be resizable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrinting an image using Open CV\n",
    "To save an image we can use **imwrite()** method. It takes the file name to be saved as and the image file itself as the arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('C:\\\\Users\\\\kshitij.saxena\\\\Desktop\\\\my_first_img.png',my_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Videos\n",
    "\n",
    "### Capturing Video from Camera\n",
    "OpenCV defines **VideoCapture()** to capture videos. It can either take the index of the camera as integer or the name of the video file. Camera index defines the camera that we need to use in case there are multiple cameras are available. Then we can capture the video frame by frame. \n",
    "After every capture, we must make sure to release the camera device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary imports, if not imported already\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "if cam.isOpened():\n",
    "    while(True):\n",
    "        ret, frame = cam.read()\n",
    "        \n",
    "        #Uncomment below line and pass 'grayScaleFrame' in imshow() method to get video in Gray Scale\n",
    "        #grayScaleFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above code requests the camera device in the first line. Then if the camera is opened loop is run to capture the video frame by frame untill 'q' key is pressed which breaks the loop. After that the camera object is released and all the windows created by Open CV are destroyed. This code will display colored video that is captured by default.\n",
    "\n",
    "***read()*** method returns an OutputArray which contains the camera frame and a boolead return value which is True if the frame is successfully captured and False other wise. This return value can be used to identify the end of video.\n",
    "\n",
    "Some video properties can be accessed by ***cam.get(propId)*** method, out of these some values can be modified as well by using ***cam.set(propId, value)*** method.\n",
    "\n",
    "List of the prop Ids is as follows - \n",
    "* CV_CAP_PROP_POS_MSEC Current position of the video file in milliseconds or video capture timestamp.\n",
    "* CV_CAP_PROP_POS_FRAMES 0-based index of the frame to be decoded/captured next.\n",
    "* CV_CAP_PROP_POS_AVI_RATIO Relative position of the video file: 0 - start of the film, 1 - end of the film.\n",
    "* CV_CAP_PROP_FRAME_WIDTH Width of the frames in the video stream.\n",
    "* CV_CAP_PROP_FRAME_HEIGHT Height of the frames in the video stream.\n",
    "* CV_CAP_PROP_FPS Frame rate.\n",
    "* CV_CAP_PROP_FOURCC 4-character code of codec.\n",
    "* CV_CAP_PROP_FRAME_COUNT Number of frames in the video file.\n",
    "* CV_CAP_PROP_FORMAT Format of the Mat objects returned by retrieve() .\n",
    "* CV_CAP_PROP_MODE Backend-specific value indicating the current capture mode.\n",
    "* CV_CAP_PROP_BRIGHTNESS Brightness of the image (only for cameras).\n",
    "* CV_CAP_PROP_CONTRAST Contrast of the image (only for cameras).\n",
    "* CV_CAP_PROP_SATURATION Saturation of the image (only for cameras).\n",
    "* CV_CAP_PROP_HUE Hue of the image (only for cameras).\n",
    "* CV_CAP_PROP_GAIN Gain of the image (only for cameras).\n",
    "* CV_CAP_PROP_EXPOSURE Exposure (only for cameras).\n",
    "* CV_CAP_PROP_CONVERT_RGB Boolean flags indicating whether images should be converted to RGB.\n",
    "* CV_CAP_PROP_WHITE_BALANCE_U The U value of the whitebalance setting (note: only supported by DC1394 v 2.x backend currently)\n",
    "* CV_CAP_PROP_WHITE_BALANCE_V The V value of the whitebalance setting (note: only supported by DC1394 v 2.x backend currently)\n",
    "* CV_CAP_PROP_RECTIFICATION Rectification flag for stereo cameras (note: only supported by DC1394 v 2.x backend currently)\n",
    "* CV_CAP_PROP_ISO_SPEED The ISO speed of the camera (note: only supported by DC1394 v 2.x backend currently)\n",
    "* CV_CAP_PROP_BUFFERSIZE Amount of frames stored in internal buffer memory (note: only supported by DC1394 v 2.x backend currently)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a Video\n",
    "The captured video can be saved frame by frame by using the ***VideoWriter()*** object. For this object, we need to specify the name of the video file, FourCC (4-byte code to specify the Video Codec), number of frames per second and frame size. Last one is the isColor flag, if it is True, encoder expects color frame, else it works with Gray Scale.\n",
    "\n",
    "Codecs are platform dependent. [FourCC website](http://www.fourcc.org/codecs.php) contains more information regarding the codecs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary imports, if not imported already\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "output = cv2.VideoWriter('my_video.avi', fourcc, 20.0, (640,480)) #arguments are Filename, Codec, FPS and Frame size respectively\n",
    "if cam.isOpened():    \n",
    "    while(True):\n",
    "        ret, frame = cam.read()\n",
    "        if ret:\n",
    "            frame = cv2.flip(frame,1)\n",
    "            output.write(frame)        \n",
    "            cv2.imshow('frames',frame)\n",
    "        \n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    cam.release()\n",
    "    output.release()\n",
    "    cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing Video from file\n",
    "Playing the video is same as capturing from camera, though one must take care of the wait in the ***waitKey()*** method. If it's too less, the video playback will be very fast else very slow. In normal cases, ***25 milliseconds*** is fine to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary imports, if not imported already\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture('my_video.avi')\n",
    "\n",
    "while(cam.isOpened()):\n",
    "    ret, frame = cam.read()\n",
    "    if ret:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow('playback',gray)\n",
    "        if(cv2.waitKey(1) & 0XFF == ord('q')):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, 'ret' is being used to check for the end of the video. As soon as the video ends, cam.read() will return the flag as false, hence breaking the loop."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
